{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b1c939-b7be-484d-882a-d9b6d5913790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 19:04:10.492009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-24 19:04:10.492030: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/dan/code/tf-digit-recognition-playground/utils.py:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if image.shape[2] is 3:\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import utils\n",
    "\n",
    "mnist_path = 'data/mnist-zoomed-to-bounds.npy'\n",
    "model_path = 'data/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942d7b25-0c7d-4229-9c66-33af34000b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_blur image.shape: (3508, 2481, 3)\n",
      "deskew() Found angle: 0.0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51578/1835018800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/home/dan/Downloads/poule-pngs/poule-011.png', cv2.IMREAD_UNCHANGED)\n",
    "img = utils.deskew(img, debug=True)\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "th, thresh = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "thresh = 255 - thresh\n",
    "\n",
    "blur=cv2.GaussianBlur(thresh, (5, 5), 1)\n",
    "# canny=cv2.Canny(blur, 5, 25)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(\n",
    "    image=blur, \n",
    "    mode=cv2.RETR_TREE,\n",
    "    method=cv2.CHAIN_APPROX_NONE\n",
    ")\n",
    "print(len(contours))\n",
    "\n",
    "# This is too naive. One way to improve could be using width/height ratio to filter\n",
    "# 1/1 would be square = group stage. 2/1 would be landscape rect = match entry, etc. \n",
    "filtered = []\n",
    "for c in contours:\n",
    "    o = 20\n",
    "    area = cv2.contourArea(c)\n",
    "    if area < 1000 or area > 5000: continue\n",
    "    perimeter = cv2.arcLength(c, True)\n",
    "    approximation = cv2.approxPolyDP(c, 0.02 * perimeter, True)\n",
    "    if len(approximation) > 100: continue\n",
    "    x, y, w, h = cv2.boundingRect(approximation)\n",
    "    if w >= h + o or w <= h - o: continue\n",
    "    filtered.append([x, y, x + w, y + h])\n",
    "\n",
    "# Naive duplicate filtering... Is there a better openCV'nic way?\n",
    "rects = []\n",
    "for r in filtered:\n",
    "    rel_tol = 0.02\n",
    "    existing = [er for er in rects if math.isclose(r[0], er[0], rel_tol=rel_tol) and math.isclose(r[1], er[1], rel_tol=rel_tol)]\n",
    "    if len(existing): continue\n",
    "    rects.append(r)\n",
    "    cv2.rectangle(img, (r[0], r[1]), (r[2], r[3]), (0, 255, 0), 3)\n",
    "\n",
    "rects = np.asarray(rects)\n",
    "    \n",
    "# Sort from left to right top to bottom\n",
    "# print('hai', rects[rects[:1].argsort()])\n",
    "print(rects)\n",
    "print(np.asarray(rects).shape)\n",
    "\n",
    "thresh = np.asarray(thresh)\n",
    "print(thresh.shape)\n",
    "\n",
    "# thresh = thresh.reshape(*thresh.shape, 1)\n",
    "thresh = np.expand_dims(thresh, axis=2)\n",
    "\n",
    "thresh = thresh / 255\n",
    "\n",
    "print(thresh.shape)\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710148a3-4870-4348-95a3-0765486e3798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e48cd-eaa5-4b3d-bf85-c25ff79d52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cached augmented data if it exists\n",
    "if os.path.isfile(mnist_path) is False:\n",
    "    print(\"Normalizing mnist data set\")\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train / 255.0\n",
    "    x_test  = x_test  / 255.0\n",
    "    \n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test  = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "    x_train = np.array([utils.zoom_to_bounds(img_array) for img_array in x_train])\n",
    "    x_test  = np.array([utils.zoom_to_bounds(img_array) for img_array in x_test])\n",
    "\n",
    "    to_save =  np.array( ([x_train, y_train], [x_test, y_test]) )\n",
    "    np.save(mnist_path, to_save)\n",
    "else:\n",
    "    print(\"Using cached mnist data set\")\n",
    "    (x_train, y_train), (x_test, y_test) = np.load(mnist_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d17c7b-094b-4d26-a24c-3159c5d93f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not overwriting if already exists!\n",
    "if os.path.isdir(model_path) is False:\n",
    "    print(\"Training model\")\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=12)\n",
    "    model.save(model_path)\n",
    "else:\n",
    "    print(\"Loading cached model\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c22f29-8609-4931-bf7d-0fcfb9e4ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180498d-698b-40c3-987d-1b35b8f2b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pngs = sorted(glob(\"data/pngs/*.png\"))\n",
    "def load_image(path):\n",
    "    image     = tf.keras.preprocessing.image.load_img(path, color_mode=\"grayscale\", target_size=(28,28), interpolation='nearest')\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    return input_arr / 255\n",
    "\n",
    "actual_data = [load_image(png) for png in pngs]\n",
    "actual_data = np.array(actual_data)\n",
    "actual_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e8902-faec-48dc-a64d-d4bd00620337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_stage = []\n",
    "for r in rects:\n",
    "    cropped = tf.image.crop_to_bounding_box(\n",
    "        blur.reshape(*blur.shape, 1), r[1], r[0], r[3] - r[1], r[2] - r[0]\n",
    "    )\n",
    "    cropped = tf.image.central_crop(\n",
    "        cropped, 0.8\n",
    "    )\n",
    "    resized = tf.image.resize(\n",
    "        cropped, (28,28), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=True\n",
    "    )\n",
    "    \n",
    "    if len(np.nonzero(resized)[0]) < 3: continue\n",
    "    \n",
    "    plt.imshow(resized, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    group_stage.append(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1be38c-d240-4820-a56b-c0a6d4c17e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 25))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "data = np.array([utils.zoom_to_bounds(img_array) for img_array in group_stage])\n",
    "predictions = probability_model(data) * 100\n",
    "for i, d in enumerate(data):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "    ax1.imshow(d, cmap=\"gray\")\n",
    "    ax2.bar(x=range(0, 10), height=predictions[i], tick_label=range(0, 10))\n",
    "    ax2.set(ylabel=\"certainty\", ylim=(0, 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
